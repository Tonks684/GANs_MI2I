{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Having successfully moved the dataset into the required location and format you are now ready to begin training of the model. This notebook is used to define the hyper-paramters neceassary for training the Pix2PixHD GAN model as well as scheduling the training within HPC environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "root_dir = '../../../'\n",
    "sys.path.append(root_dir)\n",
    "from utils.util_utils import find_file\n",
    "from slurm.commands import train_pix2pixHD\n",
    "from slurm.sbatch import submit_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(256, 256, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tifffile import imread\n",
    "import numpy as np\n",
    "f = find_file( '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float0to1/DAPI/test_A//'\n",
    ", '.tiff')\n",
    "x = imread( '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float0to1/DAPI/test_A//'+f[0])\n",
    "y = x[:,:,1]\n",
    "y = y[:,:,np.newaxis]\n",
    "z = x[:,:,0]\n",
    "z = z[:,:,np.newaxis]\n",
    "print(y.shape)\n",
    "h = np.concatenate((y,z), axis=-1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define general paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model name\n",
    "model_name = 'af_he_060923' #'dapi_HE_run_32float'\n",
    "cell_type = 'Lung'\n",
    "\n",
    "# Path for conda environment \n",
    "conda_path = os.path.join(\n",
    "    '/hpc/user_apps/bioimaging_analytics/conda_environments/pix2pixHD_CUDA11',\n",
    "#     'pytorch_1.8.1_py3.7',\n",
    ")\n",
    " \n",
    "# Path for location of source code\n",
    "repo_path = os.path.join(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/repos/gskgithub/virtual_staining/source_code/pix2pixHD_n/'\n",
    ")\n",
    "\n",
    "# Path for saving training outputs including weights and validation scores\n",
    "output_dir = os.path.join(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/experiments/Jan_AF_HnE/AFs_HE/',\n",
    "    'APPROACH_Pix2PixHD',\n",
    "    cell_type,\n",
    "    'Step1_Preprocessing',\n",
    "    'ACT2_Train',\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "# Path for chosen training file see source code for explanation of files to choose from.\n",
    "py_file = os.path.join(\n",
    "    repo_path,\n",
    "    'train_afs_he.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update model hyper-paramters\n",
    "\n",
    "See source_code/pix2pixhd/ for full explanation of each of the below hyper-parameters. \n",
    "\n",
    "#### Must update\n",
    "- **'--dataroot'**: path/to/folder/containing/train_A </br>\n",
    "- **'--data_type'**: Bit of input images. Either 8 or 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict = {}\n",
    "arg_dict['--dataroot'] = os.path.join(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float0to1//'\n",
    ")\n",
    "arg_dict['--model'] = 'pix2pixHD_af_he'\n",
    "arg_dict['--batchSize'] = '8'\n",
    "arg_dict['--checkpoints_dir'] = output_dir \n",
    "arg_dict['--label_nc'] = '2'\n",
    "arg_dict['--name'] = model_name\n",
    "arg_dict['--no_instance'] = ''\n",
    "arg_dict['--resize_or_crop'] = 'none'\n",
    "arg_dict['--input_nc'] = '2'\n",
    "arg_dict['--output_nc'] = '3'\n",
    "arg_dict['--data_type'] = '8'\n",
    "# arg_dict['--no_html'] = True\n",
    "# arg_dict['--isTrain'] = 'True'\n",
    "\n",
    "# arg_dict['--no_vgg_loss'] = ''\n",
    "arg_dict['--nThreads'] = '1'\n",
    "arg_dict['--gpu_ids'] = '0'\n",
    "arg_dict['--loadSize'] = '256'\n",
    "# arg_dict['--ndf'] = '32'\n",
    "arg_dict['--norm'] = 'instance'\n",
    "arg_dict['--use_dropout'] = ''\n",
    "# arg_dict['--dropout_variation_inf'] = 'False'\n",
    "## APEX Training only\n",
    "# arg_dict['--fp16'] = '' \n",
    "\n",
    "## Used only is retraining from epoch\n",
    "# arg_dict['--continue_train'] = ''\n",
    "# arg_dict['--which_epoch'] = 'latest'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate  and run slurm command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /hpc/projects/upt/samuel_tonks_experimental_space/repos/gskgithub/virtual_staining/source_code/pix2pixHD_n/train_afs_he.py --dataroot /hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float0to1// --model pix2pixHD_af_he --batchSize 8 --checkpoints_dir /hpc/projects/upt/samuel_tonks_experimental_space/experiments/Jan_AF_HnE/AFs_HE/APPROACH_Pix2PixHD/Lung/Step1_Preprocessing/ACT2_Train/af_he_060923 --label_nc 2 --name af_he_060923 --no_instance  --resize_or_crop none --input_nc 2 --output_nc 3 --data_type 8 --nThreads 1 --gpu_ids 0 --loadSize 256 --norm instance --use_dropout  \n"
     ]
    }
   ],
   "source": [
    "command = train_pix2pixHD(\n",
    "    py_file,\n",
    "    arg_dict\n",
    ")\n",
    "command_list = []\n",
    "command_list.append(command)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 62493370\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Submitted batch job 62493370\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Job Settings ###\n",
    "job_name = '{}'.format(model_name)\n",
    "\n",
    "node_setting = ''\n",
    "node_setting = node_setting+' --job-name={}'.format(job_name)\n",
    "node_setting = node_setting+' --time=4-00:00'\n",
    "node_setting = node_setting+' --nodes=1'\n",
    "# node_setting = node_setting+' --dependency=afterok:{}'.format('43523352')\n",
    "\n",
    "node_setting = node_setting+' --partition=gpu'\n",
    "node_setting = node_setting+' --gres=gpu:v100:1'\n",
    "node_setting = node_setting+' --ntasks-per-node=1'\n",
    "node_setting = node_setting+' --output=./slurm_outs/\"slurm-%A_%a.out\"'\n",
    "node_setting = node_setting[1:]\n",
    "\n",
    "os.makedirs('./slurm_outs', exist_ok=True)\n",
    "\n",
    "submit_array(root_dir, command_list, node_setting, job_name,repo_path, conda_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util_utils import find_file\n",
    "from tifffile import imread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float/Cy3/train_A/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-06d3456110d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m cy3_tr = find_file(\n\u001b[1;32m      2\u001b[0m \u001b[0;34m'/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float/Cy3/train_A/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m , \".tiff\")\n\u001b[0m",
      "\u001b[0;32m/hpc/projects/upt/samuel_tonks_experimental_space/repos/gskgithub/virtual_staining/utils/util_utils.py\u001b[0m in \u001b[0;36mfind_file\u001b[0;34m(folder_path, file_format, key_word)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         for f in os.listdir(\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfile_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float/Cy3/train_A/'"
     ]
    }
   ],
   "source": [
    "cy3_tr = find_file(\n",
    "'/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float/Cy3/train_A/'\n",
    ", \".tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cy3_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f9b0ad079d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcy3_tr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     x = imread(\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float0to1/Cy3/train_A/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cy3_tr' is not defined"
     ]
    }
   ],
   "source": [
    "for i in cy3_tr:\n",
    "    print(i)\n",
    "    \n",
    "    x = imread(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/jan_roger_training_eval_sets/mixed_samples/32float0to1/Cy3/train_A/'+i\n",
    ")\n",
    "    print(x[:,:,0].shape)\n",
    "    print(np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.7_notebook",
   "language": "python",
   "name": "py_3.7_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
