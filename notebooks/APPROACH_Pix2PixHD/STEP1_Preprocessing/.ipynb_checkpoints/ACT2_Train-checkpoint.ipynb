{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Having successfully moved the dataset into the required location and format you are now ready to begin training of the model. This notebook is used to define the hyper-paramters neceassary for training the Pix2PixHD GAN model as well as scheduling the training within HPC environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "root_dir = '../../../'\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from slurm.commands import train_pix2pixHD\n",
    "from slurm.sbatch import submit_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define general paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model name\n",
    "model_name = 'dummy_pix2pix'\n",
    "cell_type = 'Lung'\n",
    "\n",
    "# Path for conda environment \n",
    "conda_path = os.path.join(\n",
    "    '/hpc/user_apps/bioimaging_analytics/conda_environments/pix2pixHD_CUDA11',\n",
    "#     'pytorch_1.8.1_py3.7',\n",
    ")\n",
    " \n",
    "# Path for location of source code\n",
    "repo_path = os.path.join(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/repos/gskgithub/virtual_staining/'\n",
    ")\n",
    "\n",
    "# Path for saving training outputs including weights and validation scores\n",
    "output_dir = os.path.join(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/experiments/Tesaro-DNA-Damage/cuong_group_experiments/',\n",
    "#     'APPROACH_Pix2PixHD',\n",
    "#     cell_type,\n",
    "#     'Step1_Preprocessing',\n",
    "#     'ACT2_Train',\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "# Path for chosen training file see source code for explanation of files to choose from.\n",
    "py_file = os.path.join(\n",
    "    repo_path,\n",
    "    'train_teasro.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update model hyper-paramters\n",
    "\n",
    "See source_code/pix2pixhd/ for full explanation of each of the below hyper-parameters. \n",
    "\n",
    "#### Must update\n",
    "- **'--dataroot'**: path/to/folder/containing/train_A </br>\n",
    "- **'--data_type'**: Bit of input images. Either 8 or 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict = {}\n",
    "arg_dict['--dataroot'] = os.path.join(\n",
    "    '/hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tesaro-DNA-Damage/Data/Breast/Step1_Preprocessing/ACT1_Normalise/bf_dna_30k_nontoxic/'\n",
    ")\n",
    "arg_dict['--data_type'] = '8'\n",
    "arg_dict['--batchSize'] = '16'\n",
    "arg_dict['--checkpoints_dir'] = output_dir \n",
    "arg_dict['--label_nc'] = '0'\n",
    "arg_dict['--name'] = model_name\n",
    "arg_dict['--no_instance'] = ''\n",
    "arg_dict['--resize_or_crop'] = 'none'\n",
    "arg_dict['--input_nc'] = '3'\n",
    "arg_dict['--output_nc'] = '3'\n",
    "arg_dict['--seed'] = '42'\n",
    "# arg_dict['--no_vgg_loss'] = ''\n",
    "arg_dict['--nThreads'] = '1'\n",
    "arg_dict['--gpu_ids'] = '0'\n",
    "arg_dict['--loadSize'] = '256'\n",
    "# arg_dict['--ndf'] = '32'\n",
    "arg_dict['--norm'] = 'instance'\n",
    "arg_dict['--use_dropout'] = ''\n",
    "arg_dict['--dropout_variation_inf'] = 'False'\n",
    "## APEX Training only\n",
    "# arg_dict['--fp16'] = '' \n",
    "\n",
    "## Used only is retraining from epoch\n",
    "# arg_dict['--continue_train'] = ''\n",
    "# arg_dict['--which_epoch'] = 'latest'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate  and run slurm command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /hpc/projects/upt/samuel_tonks_experimental_space/repos/i2i_translation/source_code/pix2pixHD/train.py --dataroot /hpc/projects/upt/samuel_tonks_experimental_space/datasets/Tissue/af_he/old_train_images/ --data_type 8 --batchSize 16 --checkpoints_dir /hpc/projects/upt/samuel_tonks_experimental_space/experiments/Jan_AF_HnE/DAPI_hne/APPROACH_Pix2PixHD/Lung/Step1_Preprocessing/ACT2_Train/dapi_HE_run2 --label_nc 0 --name dapi_HE_run2 --no_instance  --resize_or_crop none --input_nc 3 --output_nc 3 --nThreads 1 --gpu_ids 0 --loadSize 256 --norm instance --use_dropout  --dropout_variation_inf False \n"
     ]
    }
   ],
   "source": [
    "command = train_pix2pixHD(\n",
    "    py_file,\n",
    "    arg_dict\n",
    ")\n",
    "command_list = []\n",
    "command_list.append(command)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 56213486\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Submitted batch job 56213486\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Job Settings ###\n",
    "job_name = '{}'.format(model_name)\n",
    "\n",
    "node_setting = ''\n",
    "node_setting = node_setting+' --job-name={}'.format(job_name)\n",
    "node_setting = node_setting+' --time=7-00:00'\n",
    "node_setting = node_setting+' --nodes=1'\n",
    "# node_setting = node_setting+' --dependency=afterok:{}'.format('43523352')\n",
    "\n",
    "node_setting = node_setting+' --partition=gpu'\n",
    "node_setting = node_setting+' --gres=gpu:a6000:1'\n",
    "node_setting = node_setting+' --ntasks-per-node=1'\n",
    "node_setting = node_setting+' --output=./slurm_outs/\"slurm-%A_%a.out\"'\n",
    "node_setting = node_setting[1:]\n",
    "\n",
    "os.makedirs('./slurm_outs', exist_ok=True)\n",
    "\n",
    "submit_array(root_dir, command_list, node_setting, job_name,repo_path, conda_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.7_notebook",
   "language": "python",
   "name": "py_3.7_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
